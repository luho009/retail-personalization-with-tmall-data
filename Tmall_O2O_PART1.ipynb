{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tmall O2O_PART1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVwpVBAAKpPL"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import datetime,time\n",
        "import os\n",
        "import random\n",
        "from datetime import date"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVfunHDcKu7k",
        "outputId": "627d8e7d-4124-4278-effb-56638bfc9ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data_online_path =r'/content/drive//MyDrive/Tmall_O2O/ccf_online_stage1_train.csv')\n",
        "#data_offline_path=r'./content/drive//MyDrive/Tmall_O2O/ccf_offline_stage1_train.csv')"
      ],
      "metadata": {
        "id": "WJgE5i_DSRs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_source_data():\n",
        "    DataPath = '/content/drive//MyDrive/Tmall_O2O/'\n",
        "    off_train = pd.read_csv(os.path.join(DataPath, 'ccf_offline_stage1_train.csv'),\n",
        "                            parse_dates=['Date_received', 'Date'])\n",
        "    off_train.columns = ['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance', 'Date_received', 'Date']\n",
        "\n",
        "    on_train = pd.read_csv(os.path.join(DataPath, 'ccf_online_stage1_train.csv'), parse_dates=['Date_received', 'Date'])\n",
        "    on_train.columns = ['User_id', 'Merchant_id', 'Action', 'Coupon_id', 'Discount_rate', 'Date_received', 'Date']\n",
        "\n",
        "    off_test = pd.read_csv(os.path.join(DataPath, 'ccf_offline_stage1_test_revised.csv'), parse_dates=['Date_received'])\n",
        "    off_test.columns = ['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance', 'Date_received']\n",
        "\n",
        "    print(off_train.info())\n",
        "    print(off_train.head(5))\n",
        "    return off_train, on_train, off_test\n",
        "\n"
      ],
      "metadata": {
        "id": "GR1zb8Qsd535"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def null_process_offline(dataset, predict=False):\n",
        "    dataset.Distance.fillna(11, inplace=True)\n",
        "    dataset.Distance = dataset.Distance.astype(int)\n",
        "    dataset.Coupon_id.fillna(0, inplace=True)\n",
        "    dataset.Coupon_id = dataset.Coupon_id.astype(int)\n",
        "    dataset.Date_received.fillna(date_null, inplace=True)\n",
        "\n",
        "    dataset[['discount_rate_x', 'discount_rate_y']] = dataset[dataset.Discount_rate.str.contains(':') == True][\n",
        "        'Discount_rate'].str.split(':', expand=True).astype(int)\n",
        "    dataset['discount_rate'] = 1 - dataset.discount_rate_y / dataset.discount_rate_x\n",
        "    dataset.discount_rate = dataset.discount_rate.fillna(dataset.Discount_rate).astype(float)\n",
        "    if predict:\n",
        "        return dataset\n",
        "    else:\n",
        "        dataset.Date.fillna(date_null, inplace=True)\n",
        "        return dataset\n",
        "\n",
        "\n",
        "def null_process_online(dataset):\n",
        "    dataset.Coupon_id.fillna(0, inplace=True)\n",
        "    dataset.Date_received.fillna(date_null, inplace=True)\n",
        "    dataset.Date.fillna(date_null, inplace=True)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "cglrdWCpf7PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(off_train, on_train, off_test):\n",
        "    time_range = ['2016-04-16', '2016-05-15']\n",
        "    dataset1 = off_train[(off_train.Date_received >= time_range[0]) & (off_train.Date_received <= time_range[1])].copy()\n",
        "    dataset1['label'] = 0\n",
        "    dataset1.loc[\n",
        "        (dataset1.Date != date_null) & (dataset1.Date - dataset1.Date_received <= datetime.timedelta(15)), 'label'] = 1\n",
        "    time_range_date_received = ['2016-01-01', '2016-03-31']\n",
        "    time_range_date = ['2016-01-01', '2016-04-15']\n",
        "    feature1_off = off_train[(off_train.Date >= time_range_date[0]) & (off_train.Date <= time_range_date[1]) | (\n",
        "            (off_train.Coupon_id == 0) & (off_train.Date_received >= time_range_date_received[0]) & (\n",
        "            off_train.Date_received <= time_range_date_received[1]))]\n",
        "    feature1_on = on_train[(on_train.Date >= time_range_date[0]) & (on_train.Date <= time_range_date[1]) | (\n",
        "            (on_train.Coupon_id == 0) & (on_train.Date_received >= time_range_date_received[0]) & (\n",
        "            on_train.Date_received <= time_range_date_received[1]))]\n",
        "    time_range = ['2016-05-16', '2016-06-15']\n",
        "    dataset2 = off_train[(off_train.Date_received >= time_range[0]) & (off_train.Date_received <= time_range[1])]\n",
        "    dataset2['label'] = 0\n",
        "    dataset2.loc[\n",
        "        (dataset2.Date != date_null) & (dataset2.Date - dataset2.Date_received <= datetime.timedelta(15)), 'label'] = 1\n",
        "   \n",
        "    time_range_date_received = ['2016-02-01', '2016-04-30']\n",
        "    time_range_date = ['2016-02-01', '2016-05-15']\n",
        "    feature2_off = off_train[(off_train.Date >= time_range_date[0]) & (off_train.Date <= time_range_date[1]) | (\n",
        "            (off_train.Coupon_id == 0) & (off_train.Date_received >= time_range_date_received[0]) & (\n",
        "            off_train.Date_received <= time_range_date_received[1]))]\n",
        "  \n",
        "    feature2_on = on_train[(on_train.Date >= time_range_date[0]) & (on_train.Date <= time_range_date[1]) | (\n",
        "            (on_train.Coupon_id == 0) & (on_train.Date_received >= time_range_date_received[0]) & (\n",
        "            on_train.Date_received <= time_range_date_received[1]))]\n",
        "\n",
        "   \n",
        "    dataset3 = off_test\n",
        "    \n",
        "    time_range = ['2016-03-16', '2016-06-30']\n",
        "    feature3_off = off_train[((off_train.Date >= time_range[0]) & (off_train.Date <= time_range[1])) | (\n",
        "            (off_train.Coupon_id == 0) & (off_train.Date_received >= time_range[0]) & (\n",
        "            off_train.Date_received <= time_range[1]))]\n",
        " \n",
        "    feature3_on = on_train[((on_train.Date >= time_range[0]) & (on_train.Date <= time_range[1])) | (\n",
        "            (on_train.Coupon_id == 0) & (on_train.Date_received >= time_range[0]) & (\n",
        "            on_train.Date_received <= time_range[1]))]\n",
        "\n",
        "    \n",
        "    ProcessDataSet1 = get_features(dataset1, feature1_off, feature1_on)\n",
        "    ProcessDataSet2 = get_features(dataset2, feature2_off, feature2_on)\n",
        "    ProcessDataSet3 = get_features(dataset3, feature3_off, feature3_on)\n",
        "\n",
        "    return ProcessDataSet1, ProcessDataSet2, ProcessDataSet3"
      ],
      "metadata": {
        "id": "61gAhK3kf-Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(dataset, feature_off, feature_on):\n",
        "    dataset = get_offline_features(dataset, feature_off)\n",
        "    return get_online_features(feature_on, dataset)"
      ],
      "metadata": {
        "id": "2A49rXxbi-Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_offline_features(X, offline):\n",
        "   \n",
        "    print(len(X), len(X.columns))\n",
        "\n",
        "    temp = offline[offline.Coupon_id != 0] \n",
        "    coupon_consume = temp[temp.Date != date_null] \n",
        "    coupon_no_consume = temp[temp.Date == date_null] \n",
        "\n",
        "    user_coupon_consume = coupon_consume.groupby('User_id')\n",
        "\n",
        "    X['weekday'] = X.Date_received.dt.weekday\n",
        "    X['day'] = X.Date_received.dt.day\n",
        "\n",
        "    '''user features'''\n",
        "\n",
        "    \n",
        "    temp = user_coupon_consume.size().reset_index(name='offline_user_coupon_consume')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "   \n",
        "\n",
        "    temp = coupon_no_consume.groupby('User_id').size().reset_index(name='offline_user_coupon_no_consume')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "    X['offline_user_coupon_receive'] = X.offline_user_coupon_consume.fillna(0) + X.offline_user_coupon_no_consume.fillna(0)\n",
        "\n",
        "   \n",
        "    X['offline_user_coupon_consume'] = X.offline_user_coupon_consume / X.offline_user_coupon_receive\n",
        "\n",
        "    temp = offline[(offline.Coupon_id == 0) & (offline.Date != date_null)]\n",
        "    temp1 = temp.groupby('User_id').size().reset_index(name='offline_nocoupon_consume')\n",
        "    X = pd.merge(X, temp1, how='left', on='User_id')\n",
        "\n",
        "  \n",
        "    X['total_consumptions'] = X.offline_user_coupon_consume + X.offline_nocoupon_consume\n",
        "\n",
        "    X['%coupon_used_in_totalconsumption'] = X.offline_user_coupon_consume / X.total_consumptions\n",
        "\n",
        "    temp = pd.merge(temp, temp.groupby('User_id').Date.max().reset_index(name='max'))\n",
        "    temp = pd.merge(temp, temp.groupby('User_id').Date.min().reset_index(name='min'))\n",
        "    temp = pd.merge(temp, temp.groupby('User_id').size().reset_index(name='len'))\n",
        "    temp['offline_consumed_daygap'] = ((temp['max'] - temp['min']).dt.days / (temp['len'] - 1))\n",
        "    temp = temp.drop_duplicates('User_id')\n",
        "    X = pd.merge(X, temp[['User_id', 'offline_consumed_daygap']], how='left', on='User_id')\n",
        "\n",
        "    temp = coupon_consume.copy()\n",
        "    temp['days'] = (temp.Date - temp.Date_received).dt.days\n",
        "    temp = (temp.groupby('User_id').days.sum() / temp.groupby('User_id').size()).reset_index(name='offline_days_from_received_to_consumed')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "    temp = user_coupon_consume.discount_rate.mean().reset_index(name='offline_consumed_avg_discountrate')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "    temp = offline[(offline.Coupon_id != 0) & (offline.Date != date_null) & (offline.Distance != 11)]\n",
        "    temp = temp.groupby('User_id').Distance\n",
        "    temp = pd.merge(temp.count().reset_index(name='x'), temp.sum().reset_index(name='y'), on='User_id')\n",
        "    temp['avg_distance_consumed'] = temp.y / temp.x\n",
        "    temp = temp[['User_id', 'avg_distance_consumed']]\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "    temp = coupon_consume[coupon_consume.Distance != 11]\n",
        "    temp = temp.groupby('User_id').Distance.min().reset_index(name='min_distance_consumed')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "    temp = coupon_consume[coupon_consume.Distance != 11]\n",
        "    temp = temp.groupby('User_id').Distance.max().reset_index(name='max_distance_consumed')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "    discount_types = [\n",
        "        '0.2', '0.5', '0.6', '0.7', '0.75', '0.8', '0.85', '0.9', '0.95', '30:20', '50:30', '10:5',\n",
        "        '20:10', '100:50', '200:100', '50:20', '30:10', '150:50', '100:30', '20:5', '200:50', '5:1',\n",
        "        '50:10', '100:20', '150:30', '30:5', '300:50', '200:30', '150:20', '10:1', '50:5', '100:10',\n",
        "        '200:20', '300:30', '150:10', '300:20', '500:30', '20:1', '100:5', '200:10', '30:1', '150:5',\n",
        "        '300:10', '200:5', '50:1', '100:1',\n",
        "    ]\n",
        "    X['discount_type'] = -1\n",
        "    for k, v in enumerate(discount_types):\n",
        "        X.loc[X.Discount_rate == v, 'discount_type'] = k\n",
        "\n",
        "  \n",
        "    temp = offline.groupby(['User_id', 'Discount_rate']).size().reset_index(name='offline_coupon_received_bytype')\n",
        "    X = pd.merge(X, temp, how='left', on=['User_id', 'Discount_rate'])\n",
        "\n",
        "   \n",
        "    temp = coupon_consume.groupby(['User_id', 'Discount_rate']).size().reset_index(name='offline_coupon_consumed_bytype')\n",
        "    X = pd.merge(X, temp, how='left', on=['User_id', 'Discount_rate'])\n",
        "\n",
        "\n",
        "    X['%ofcouponused_bytype'] = X.offline_coupon_consumed_bytype / X.offline_coupon_received_bytype\n",
        "\n",
        "\n",
        "    '''offline merchant features'''\n",
        "\n",
        "   \n",
        "    temp = offline[offline.Date != date_null].groupby('Merchant_id').size().reset_index(name='offline_merchant_no.oforder')\n",
        "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
        "\n",
        "   \n",
        "    temp = coupon_consume.groupby('Merchant_id').size().reset_index(name='offline_merchant_coupon_recieved_consumed')\n",
        "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
        "\n",
        " \n",
        "    temp = offline[offline.Date_received != date_null].groupby('Merchant_id').size().reset_index(name='offline_merchant_coupon_recieved')\n",
        "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
        "\n",
        "    X['offline_merchant_%coupon_used'] = X.offline_merchant_coupon_recieved_consumed / X.offline_merchant_coupon_recieved\n",
        "\n",
        "  \n",
        "    temp = coupon_consume.groupby('Merchant_id').discount_rate.mean().reset_index(name='offline_merchant_avgdiscountrate')\n",
        "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
        "\n",
        "\n",
        "    print(len(X), len(X.columns))\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i4eFeusTjCDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_online_features(online, X):\n",
        "    \n",
        "    \n",
        "    temp = online.groupby('User_id').size().reset_index(name='online_user_actions')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "  \n",
        "    temp = online[online.Action == 0].groupby('User_id').size().reset_index(name='online_user_clicks')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "   \n",
        "    X['online_CTR'] = X.online_user_clicks / X.online_user_actions\n",
        "\n",
        "   \n",
        "    temp = online[online.Action == 1].groupby('User_id').size().reset_index(name='online_user_purchase')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "   \n",
        "    X['online_PurchaseRate'] = X.online_user_purchase / X.online_user_actions\n",
        "\n",
        "   \n",
        "    temp = online[online.Coupon_id != 0].groupby('User_id').size().reset_index(name='online_user_coupon_receive')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "    \n",
        "    X['%online_user_coupon_received'] = X.online_user_coupon_receive / X.online_user_actions\n",
        "\n",
        "   \n",
        "    temp = online[(online.Date != date_null) & (online.Coupon_id != 0)]\n",
        "    temp = temp.groupby('User_id').size().reset_index(name='online_user_coupon_consume')\n",
        "    X = pd.merge(X, temp, how='left', on='User_id')\n",
        "\n",
        "   \n",
        "    X['online_user_couponusage'] = X.online_user_coupon_consume / X.online_user_coupon_receive\n",
        "\n",
        "\n",
        "    X['%offline_consumedwithcoupon_inO2O'] = X.offline_user_coupon_consume / (X.online_user_coupon_consume + X.offline_user_coupon_consume )\n",
        "\n",
        "    \n",
        "    X['%offline_receivedcoupon_inO2O'] = X.offline_user_coupon_receive / (X.online_user_coupon_receive + X.offline_user_coupon_receive)\n",
        "\n",
        "    print(len(X), len(X.columns))\n",
        "    print('----------')\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "Hr6S8CJXlnp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        " \n",
        "    start = datetime.datetime.now()\n",
        "    print(start.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "    date_null = pd.to_datetime('1970-01-01', format='%Y-%m-%d')\n",
        "\n",
        "    pd.set_option('expand_frame_repr', False)\n",
        "    pd.set_option('display.max_rows', 200)\n",
        "    pd.set_option('display.max_columns', 200)\n",
        "\n",
        " \n",
        "    FeaturePath = '/content/drive//MyDrive/Tmall_O2O/'\n",
        "\n",
        "    off_train, on_train, off_test = get_source_data()\n",
        "\n",
        "    \n",
        "    off_train = null_process_offline(off_train, predict=False)\n",
        "    on_train = null_process_online(on_train)\n",
        "    off_test = null_process_offline(off_test, predict=True)\n",
        "\n",
        "    ProcessDataSet1, ProcessDataSet2, ProcessDataSet3 = data_process(off_train, on_train, off_test)\n",
        "\n",
        "    ProcessDataSet1.to_csv(os.path.join(FeaturePath, 'ProcessDataSet1.csv'), index=None)\n",
        "\n",
        "    ProcessDataSet2.to_csv(os.path.join(FeaturePath, 'ProcessDataSet2.csv'), index=None)\n",
        "\n",
        "    ProcessDataSet3.to_csv(os.path.join(FeaturePath, 'ProcessDataSet3.csv'), index=None)\n",
        "\n",
        "    print((datetime.datetime.now() - start).seconds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBGC_IOij4Ls",
        "outputId": "a9dcc05b-fe19-4fb5-d002-09f1c36f02c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-01 12:47:04\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1754884 entries, 0 to 1754883\n",
            "Data columns (total 7 columns):\n",
            " #   Column         Dtype         \n",
            "---  ------         -----         \n",
            " 0   User_id        int64         \n",
            " 1   Merchant_id    int64         \n",
            " 2   Coupon_id      float64       \n",
            " 3   Discount_rate  object        \n",
            " 4   Distance       float64       \n",
            " 5   Date_received  datetime64[ns]\n",
            " 6   Date           datetime64[ns]\n",
            "dtypes: datetime64[ns](2), float64(2), int64(2), object(1)\n",
            "memory usage: 93.7+ MB\n",
            "None\n",
            "   User_id  Merchant_id  Coupon_id Discount_rate  Distance Date_received       Date\n",
            "0  1439408         2632        NaN           NaN       0.0           NaT 2016-02-17\n",
            "1  1439408         4663    11002.0        150:20       1.0    2016-05-28        NaT\n",
            "2  1439408         2632     8591.0          20:1       0.0    2016-02-17        NaT\n",
            "3  1439408         2632     1078.0          20:1       0.0    2016-03-19        NaT\n",
            "4  1439408         2632     8591.0          20:1       0.0    2016-06-13        NaT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132943 11\n",
            "132943 34\n",
            "132943 45\n",
            "----------\n",
            "252586 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252586 34\n",
            "252586 45\n",
            "----------\n",
            "113640 9\n",
            "113640 32\n",
            "113640 43\n",
            "----------\n",
            "65\n"
          ]
        }
      ]
    }
  ]
}